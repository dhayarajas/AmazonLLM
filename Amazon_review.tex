\documentclass[12pt,a4paper]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{url}
\urlstyle{same}
\def\UrlBreaks{\do\/\do-\do?\do&\do=\do_}
\urlstyle{same}

% Page setup
\geometry{margin=1in}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue
}

% Title and author information
\title{Enhancing Product Recommendations through Large Language Model and Significant Latent Core Factor SVD: Insights from Amazon Reviews}
\author{
    R. Dhayanidhi\\
    Research Scholar\\
    Dept of CSE\\
    Vel Tech Rangarajan Dr.Sagunthala R \& D Institute of Science and Technology, Chennai, India.\\
    \texttt{Dhayanidhi.r@gmail.com}\\
    \and
    N.R. Rajalakshmi\\
    Professor\\
    Dept of CSE\\
    Vel Tech Rangarajan Dr.Sagunthala R \& D Institute of Science and Technology, Chennai, India.\\
    \texttt{drnrrajalakshmi@veltech.edu.in}
}
\date{}

\begin{document}

\maketitle

\begin{abstract}
In recent times, e-commerce platforms provide users with an overwhelming number of choices, making the shopping framework increasingly complex. This inevitably creates an information overload problem, particularly in smart retail environments where Internet of Things (IoT) devices generate real-time shopping data. The resolution to this issue in e-commerce is a personalized recommendation model using Machine Learning approaches. Users frequently become confused when experiencing excessive information and may not identify the most relevant products. Many existing studies have investigated product recommendation using Singular Value Decomposition (SVD), which is one of the most efficient techniques for recommending products. However, traditional SVD struggles when working with unseen data, leading to delays or inappropriate product recommendations. To overcome this problem, the proposed research employs a significant latent core factor SVD. The proposed technique includes decomposing a large and sparse matrix that captures real-time interactions between users and products into matrices that permit the proposed model to forecast personalized product recommendations based on existing data. The proposed research employs Large Language Models (LLMs) to improve the process of feature extraction with data imputation features after pre-processing. This helps to fill missing values more accurately based on existing data, which enhances the performance of the proposed model and leads to personalized recommendations. The proposed research employs the Amazon product review dataset to evaluate the proposed significant latent core SVD. The performance of the proposed model is evaluated using the performance metrics of Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). When compared to traditional SVD and state-of-the-art methods such as LightGCN and BERT4Rec, the proposed significant latent core factor SVD achieves lower error rates.
\end{abstract}

\textbf{Keywords:} E-Commerce, Product Recommendation System, Machine Learning, Singular Value Decomposition, Large Language Model, Internet of Things, Smart Retail, Edge Computing

\section{Introduction}

In the era of smart retail and Internet of Things (IoT)-enabled shopping environments, users face an unprecedented challenge: information overload in personalized shopping experiences. Modern IoT devices, including smart shelves, RFID tags, mobile applications, and wearable devices, continuously generate vast amounts of real-time shopping data~\cite{ref1}. This proliferation of data creates a critical problem where users become overwhelmed by choices and struggle to identify relevant products that match their preferences and needs~\cite{ref2}. Information overload in IoT-based shopping is defined as the stress induced by accepting more data than necessary to make purchasing decisions, compounded by the need to process this information within time constraints~\cite{ref3}. This problem significantly limits users' ability to review options and select among numerous alternative products available in online and smart retail markets.

To address this challenge, information science and technology have developed data filtering tools, with recommendation systems emerging as one of the most effective solutions since their development in the early 1990s~\cite{ref4}. These systems are designed as software tools that assist users in selecting items and other entities by leveraging their preferences and behavior patterns~\cite{ref5}. In recent years, recommendation systems have become integral components of e-commerce platforms, particularly in IoT-enabled smart retail environments where real-time data from multiple sources must be processed efficiently~\cite{ref6}. However, users continue to experience difficulties in discovering beneficial information from massive databases, especially when shopping through IoT devices with limited computational resources and display capabilities~\cite{ref7}. 

The recommendation systems in IoT-based e-commerce face several critical challenges: (1) the appropriateness of recommendations is limited because product characteristics and user boundaries are inadequately mined from sparse IoT sensor data, (2) single recommendation paradigms fail to fulfill diverse user demands across different IoT contexts (mobile, wearable, smart home), and (3) static metrics and designs lead to inflexibility in recommendation systems that must adapt to dynamic IoT environments~\cite{ref8}. From a technical perspective, recommendation systems operate using various approaches, including Content-Based Filtering (CBF), Demographic Filtering (DF), Collaborative Filtering (CF), and Knowledge-Based Filtering (KBF)~\cite{ref9}. User preferences across unique items can be predicted using ranking patterns that provide lists of recommended products through personalized assessments~\cite{ref10}.

Generally, the architecture of recommendation systems relies on databases that save and sequentially update product and rating descriptions provided by users. Due to these services, particularly filtering and clustering, recommendation systems are broadly employed in e-commerce, helping users discover relevant and recent items~\cite{ref11}. Moreover, products are recommended based on similar metrics prevailing among items and users in collaborative filtering~\cite{ref12}. There are two types of collaborative filtering: model-based collaborative filtering and neighborhood-based collaborative filtering. Neighborhood-based collaborative filtering comprises user-based and item-based approaches~\cite{ref13}. The user-based approach recommends items that are liked by users with similar preferences, while the item-based approach recommends items based on similar properties~\cite{ref14}. Recently, several matrix factorization techniques have been employed for collaborative filtering. Conversely, items might be recommended based on product services or specifications in content-based filtering~\cite{ref15}. 

Product recommendation depends on user preference models derived from searches, shopping cart inclusions, likes, browsing history, orders, comments, and favorites. In IoT-based smart retail environments, these models must also incorporate real-time sensor data from smart devices, location information, and contextual shopping patterns~\cite{ref16}. User client reporting tracks shopping cart, browsing, and clicking activities to offer real-time feedback to users~\cite{ref17}. Using Spark or Storm streaming evaluations, real-time user preferences are generated, though significant challenges remain in handling both user and product relationships and the combined demands on storage access and space performance for online services, particularly in edge computing scenarios~\cite{ref18}. 

Consequently, the applicability of Machine Learning in e-commerce has wide-ranging forecasts and offers massive emergent opportunities for e-commerce enterprises, especially in IoT-enabled smart retail environments~\cite{ref19}. Machine Learning can comprehend customized recommendation systems by analyzing vast product information and user data, thus enhancing shopping experiences and purchase conversion rates. It aids in generating extremely customized product recommendations that have significantly enhanced user loyalty and purchase willingness~\cite{ref20}. However, while SVD is a robust tool in e-commerce for product recommendation, it has several drawbacks including data sparsity, computational expenses, and static nature. Traditional SVD struggles when unseen data is introduced, which may delay the recommendation process, particularly problematic in real-time IoT shopping scenarios where latency is critical. To overcome these problems, there is a need to incorporate SVD with enhanced techniques that can handle sparse data and provide real-time recommendations suitable for edge devices.

Hence, the proposed research introduces an enhanced product recommendation model for Amazon products that is suitable for IoT-based smart retail environments. The proposed research employs Large Language Models (LLMs) to enhance the feature extraction process, creating additional summaries or descriptions of products based on existing information. This aids in generating precise content for the recommendation model, particularly valuable for addressing the cold start problem when new users or products enter the system. To recommend products, the proposed research employs significant latent core factor SVD, which is mathematically distinct from traditional SVD variants. The proposed model is evaluated using the Amazon product review dataset, and its performance is assessed using Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) metrics, with comparisons to state-of-the-art methods including LightGCN and BERT4Rec.

\subsection{Research Contribution}

The main objective of the proposed research is follows:

\begin{itemize}
\item To develop an efficient recommendation model for Amazon products using Amazon product review dataset.
\item To enhance the feature extraction by using LLM which generates extra summaries or description of the products based on existing information
\item To provide precise recommendation to the users about products by proposed significant latent core factor SVD.
\end{itemize}

\subsection{Paper organization}

The structure of the research paper is organized with overview in Section 1, the review of existing studies involved in recommendation system by diverse algorithms are deliberated in section 2 along with research gaps. Section 3 deliberates the proposed methodology and the process involved. The results achieved by the proposed model is represented in the Section 4. The conclusion and future work of the proposed model is represented in Section 5.

\section{Literature Review}

The study~\cite{ref21} demonstrated enhanced product demonstration method by collaborative filtering on the basis of triangle similarity. The approached study has considered common ratings and which were not generally rated by the pairs of uses. The study has been evaluated by the six dataset with satisfactory performance. Moreover, the study~\cite{ref22} has used product recommendation system based on hybrid model by enhanced Apriori algorithms. The study has employed PCA (Principle Component Analysis) for data reduction which has aided to minimize the complexity. The study has attained better performance with 0.7869. Besides, the study~\cite{ref23} implemented sentiment based product recommendation model by ML algorithms. The study has been evaluated by dataset from kaggle. The performance of the study has been evaluated by performance metrics of accuracy, precision, recall and F1-score. The objective of the study~\cite{ref24} has been forecast the ratings to recommend the products to the users by collaborative filtering algorithms which has included ALS (Alternated Least Squares), SVD (Singular Value Decomposition) along with to recommend products by KNNBasic (K-Nearest Neighbor). To detect the abnormalities K-means clustering has employed. The SVD techniques has been outperformed. Similarly, the study~\cite{ref25} has employed hybrid ML combination and clustering algorithm to recommend products for the users by k-means clustering algorithm and Apriori rule with satisfactory performance. Literally, the study~\cite{ref26} demonstrated product recommendation which included commodity data set and evaluating rankings of user with commodity interest. The study has employed fusion recommendation algorithm on the basis of frequent item set mining with better performance. Similarly, the study~\cite{ref27} has employed classification approach based on sentimental analysis by BH -- GWO (Black Hole-based Grey Wolf Optimization) Fuzzy. The study optimized the approached technique by adaptive fuzzy classifier with better performance when compare to SVM (Support Vector Machine), Fuzzy, NN (Neural Network) and KNN. Literally, the study~\cite{ref28} demonstrated recommendation system in e-commerce by HAR -- KNN (Hybrid Action-Related K-Nearest Neighbour) to deepen the user behavior matrix by feature vectors. The study has employed KNN to categorize the real-time and online users and analyze the similarity from huge target users from massive amount of data with average error value in MSE and RMSE with 0.7201 and 0.7322. Likewise, the study~\cite{ref29} has employed OCA (Ordered Clustering based Algorithm) to minimize the data sparsity and the cold start issues in E-commerce recommendation systems. The study has used collaborative filtering to groups the users depends on their preferences. The performance of the approach has been evaluated by the performance metrics. Correspondingly, the objective of the study~\cite{ref30} has implemented recommendation system to obtained precised outcomes based on the behavior of the customers and collaborating with mathematical analysis which has assisted for the decision making process in the E-commerce platform with satisfactory performance.

Moreover, the study~\cite{ref31} has demonstrated recommendation system on the basis of semantic context to investigate the semantic combinations among items achieved by using products by the users. To choose the top N neighbors, collaborative filtering and mining sequential patterns with satisfactory performance. Besides, the study~\cite{ref32} demonstrated DeepIDRS (Item Description and Review Based Deep Sequential Recommendation) by analyzing the review of the users. The study has been evaluated by the three real-world Amazon dataset. The study has two level hierarchical structure which has included bidirectional encoder to deliberate textual details of the item and attention based sequential recommendation model to embedding the details from the previous layer with better performance. Literally, the objective of the study~\cite{ref33} has to develop a recommendation system by RHRM (review of the helpfulness-based recommendation methodology) which has assisted for personalized recommendation. The study has incorporated CNN (Convolutional Neural Network) and Bi-LSTM (Bidirectional Long Short Term Memory). The respective study has been evaluated by the Amazon Book dataset with satisfactory performance. Similarly, the study~\cite{ref34} demonstrated SEMMRec (Semantic-Enabled Markov Model Recommendation) system that has feed metadata of products and purchase history of customers and extract the relevant semantic and sequential product knowledge according to the textual and usage characteristics through found resemblance among product based on their features by TF-IDF and Doc2vec of distributional hypothesis methods with average performance. Moreover, the study~\cite{ref35} has demonstrated hybrid recommendation system based on user collaborative filtering and content filtering. To swap the conventional user-item rating matrix, the study has combined user feature rating matrix and user rating with item features. The study has achieved satisfactory performance with k-means clustering. Besides, the study~\cite{ref36} demonstrated recommendation model of SCSHRS (Sparsity and Cold Start Aware Hybrid Recommended System) to overwhelm CSP and data sparsity in RS. The study has included 4 stages in each stages diverse techniques has been employed to enhance the process such as Ant Lion based k-means clustering has been used to group the similar users, HOSVD (Higher Order Singular Value Decomposition) has been used to minimize the dimensions of the data and finally ANFIS (Adaptive Neuro-Fuzzy Inference System) has been used to forecast the output with satisfactory performance. As the prevailing algorithms has faced some issues in user preferences and product relationships, ML methods like collaborative filtering and DL are involved in the study~\cite{ref37} for tackling the issues by enhancing the classification accuracy and personalized recommendations. Additionally, in order to tackle the issues, the study~\cite{ref38} has implemented the combination of collaborative filtering, Bayesian ranking with Light GBM and DNN, popularity-based method which has enhanced the accuracy with average values in terms of MAP@K and MAR@K. As the ML methods has faced several challenges such as data sparsity and reliability,~\cite{ref39} has utilized the collaborative filtering for tackling the issues of content related techniques and hybrid methods which are difficult along with a quality. The study~\cite{ref40} has tackled the overload information by utilizing the RSVD (Rating Singular Value Decomposition) and has obtained average level of accuracy in contrast with the collaborative filtering techniques and has dynamically tackled the sparsity issue.

The study~\cite{ref41} has utilized the PCA-SVD (Singular-Value Decomposition) for decreasing the dimensionality and the K-means for clustering for improving the image regarding the recommendations. The results has obtained average outcomes in terms of increased quality of cluster. Various ML methods like KNN baseline, CO-clustering and SVD has been suggested~\cite{ref42} for tackling the issues of producing appropriate and adapted recommendations. As a result, the suggested algorithms has been examined in terms of MSE, FCP, RMSE, MAE , NDCG which has been implemented to the GUI after the production of results for an enhanced performance. The study~\cite{ref43} has utilized the combination of collaborative and content based filtering has been suggested for tackling the problems of sparse data and transferring the user partialities. As a result, adaptive user communications and improved cooperation has been obtained. Also, KNN and matrix factorization with the utilization of SVD are involved in the study~\cite{ref44} for tackling the problems of cold start and inaccurate recommendations and has obtained average results in terms of precision and image quality by the hybrid method. Alternatively, the PHOTSVD (Parallel Higher-Order Tensor Singular-Value Decomposition) algorithm has been suggested~\cite{ref45} to control the numerous entities for stronger recommendations and for tackling the issues of cold start and data bias. As a result, the obtained PMRS has an average performance in contrast with the traditional; systems in terms of better quality. Similarly, SVD has been suggested by the study~\cite{ref46} for tackling the issues of accuracy, involvement of users and the computational effectiveness. The outcomes obtained by the study has enhanced the quality in terms of precision, recall and F1 score, click by rates and a stronger computing performance in recommendations. The study~\cite{ref47} has utilized SVD and its alternatives for tackling the issues of data sparsity, scalability and the cold start and the outcomes has incorporated the accuracy of recommendation in terms of metrics like spearman's rank correlation coefficient and RMSE. Correspondingly, the study~\cite{ref48} has utilized the improved SVD with its adjacent neighbour's techniques for enhancing the data clustering and classification which has purposed to decrease the usage of resource and enhance the performance of the system recommendation. Alternatively, the SVD algorithms has been implemented~\cite{ref49} with the utilization of MPI (Message Passing Interface), spark and hadoop for allowing the scalability and parallelization fir the issue of using the large scale data in the systems of recommendation. As a result, the outcomes obtained has enhanced the performance in contrast with the conventional systems. Subsequently, dynamic methods such as adaptive KNN with SVD ECF (Extended Collaborative Filtering) has been used by the study~\cite{ref50} for addressing the problem of data sparsity and cold start. As a result, enhanced recommendations has been obtained in the implementation of those algorithms.

\subsection{Problem Identification}

\begin{itemize}
\item The existing study has represented results based on single case study and it has included inadequate demographical data which has led to the reduction of overall quality of the customer groups~\cite{ref22}.
\item The limitations of the existing study has faced privacy issues and scalability during handle the information of the users~\cite{ref34}.
\item The limitations of the study~\cite{ref40} involves the need for excess appropriate content-based recommendation systems which has tackled the sparsity issues and frequently a restriction in collaborative filtering methods.
\end{itemize}

\section{Research Methodology}

In recommendation system, SVD plays a significant role because it potentially reduces the user-item interaction dimensionality matrix that improves the performance of the proposed. However, the traditional SVD faced some limitations. To address this, the proposed research employs significant latent core factor SVD. The overall process of proposed research is represented in Figure~\ref{fig:overall_process}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{media/image1.png}
\caption{Overall Process of Proposed Research}
\label{fig:overall_process}
\end{figure}

Figure~\ref{fig:overall_process} depicts the overall process of proposed research. Initially, the proposed research load the Amazon product review dataset which includes the user ID, products purchased by the users, liked products and frequently searched products. The loaded dataset is processed with pre-processing however, there is a limitation in pre-processing, there is massive difference among actual rating and filling rating during the pre-processing. To resolve this issue, the proposed research employs LLM with data imputing features which is train by the dataset and aids to fill the data more accurately when compare to the pre-processing. The processed data is fed as an input to the proposed significant latent code SVD which aids to minimize the sparse and large matrices dimensionality which deliberate interaction of users with products. This drop seizures latent factors leveraging preferences of user and characteristics of item that permitting for more precise recommendation. By employing the proposed significant latent core factor SVD. The products are recommended to the users based on their user ID. Finally, the performance of the proposed model is evaluated by MSE and RMSE.

\subsection{Dataset Description}

The proposed research employs Amazon product review dataset. The dataset is available at: \url{https://www.kaggle.com/datasets/asaniczka/amazon-products-dataset-2023-1-4m-products?select=amazon_products.csv}. Amazon is one of the largest retailers in the USA which retails across 12 million products throughout the world. This dataset includes best sell products, the optimal range for a product in a provided category, which SEO (Search Engine Optimization) headings produce the most sales. The respective dataset includes 1.4 million details of Amazon products which contains heading, ratings, sales data and number of reviews from September 2023.

\subsection{Pre-Processing}

The proposed research employs pre-processing is to convert the raw data into structured data. This process improves the accuracy of proposed research by confirming which the dataset provided into algorithm is relevant, clean and exact format. This involves correcting errors by removing irrelevant data that aids the proposed model to make precise predictions on the basis of high quality data. The quality of dataset is majorly enhanced by using pre-processing techniques like data transformation and noise reduction. This contains encoding the classified variables, removing outliers and normalizing data that permits proposed model to concentrate on the more information perspective of the data. The proposed research employs LLM to fill the missing values efficiently which enhance the recommendation system of the proposed model.

\subsection{Data Imputation Using Large Language Models}

The conventional techniques for managing missing values, such as K-Nearest Neighbors (KNN), mean imputation, and Generative Adversarial Networks (GANs), fail to capture the complex relationships between variables in recommendation systems. In existing studies, GANs struggle with the depth of semantic interpretation needed for efficient recommendations. Additionally, conventional GANs focus on creating new data samples rather than intelligently imputing missing values based on contextual information. In contrast, the proposed Large Language Model (LLM) approach offers dynamic recommendations based on real-time user interactions and contextual data, making it particularly suitable for IoT-based smart retail environments.

\subsubsection{LLM Architecture and Training}

The proposed LLM technique leverages a combination of BART (Bidirectional and Auto-Regressive Transformer) and GPT (Generative Pre-trained Transformer) architectures. Specifically, we employ Facebook's BART-base model, which is a denoising autoencoder that combines bidirectional encoding (like BERT) with autoregressive decoding (like GPT). This architecture is particularly well-suited for sequence-to-sequence tasks such as generating product descriptions and imputing missing ratings.

\textbf{Input Representation:}
For each product in the dataset, we construct a comprehensive input text that incorporates multiple features:
\begin{equation}
\text{input\_text} = f(\text{title}, \text{category}, \text{price}, \text{reviews\_count}, \text{bought\_last\_month}, \text{is\_best\_seller})
\label{eq:llm_input}
\end{equation}
where $f$ concatenates these features into a structured prompt: ``Describe this product: Product title [title], Category name [category], Category id [id], [reviews] reviewers count, [price] price, bought In LastMonth [count], isBestSeller [status].''

\textbf{Target Representation:}
The target text is constructed as: ``The estimated star is [rating]'', where [rating] is the actual star rating (1-5) for training or the predicted rating for inference.

\textbf{Training Process:}
The LLM is fine-tuned on the Amazon product review dataset using the following procedure:
\begin{enumerate}
\item \textbf{Data Preparation:} The dataset is split into training (90\%) and validation (10\%) sets. Each sample consists of an input text (product features) and a target text (star rating).
\item \textbf{Tokenization:} Input and target texts are tokenized using the BART tokenizer with a maximum length of 512 tokens for inputs and 100 tokens for targets.
\item \textbf{Model Configuration:} The BART-base model (140M parameters) is used as the base architecture. Training hyperparameters include: learning rate of $5 \times 10^{-5}$, batch size of 4 per device, weight decay of 0.01, and 1 training epoch.
\item \textbf{Fine-tuning:} The model is fine-tuned using the Hugging Face Trainer API with sequence-to-sequence language modeling objective, enabling it to learn the mapping from product features to ratings.
\end{enumerate}

\subsubsection{Missing Value Imputation Process}

During pre-processing, missing values are filled using the LLM approach through the following steps:

\textbf{1. Prompt Generation:}
For products with missing ratings, the LLM generates a prompt using available information:
\begin{equation}
P_{\text{missing}} = \text{LLM\_encode}(\text{input\_text}_{\text{product}})
\label{eq:prompt_gen}
\end{equation}

\textbf{2. Rating Prediction:}
The LLM processes the prompt and generates a probability distribution over possible rating values. The predicted rating is extracted from the model's output:
\begin{equation}
\hat{r} = \text{argmax}_{r \in \{1,2,3,4,5\}} P(r | P_{\text{missing}})
\label{eq:rating_pred}
\end{equation}

\textbf{3. Semantic Validation:}
Unlike statistical imputation methods, the LLM ensures that imputed values are semantically meaningful. For example, if a product has high price, many reviews, and best-seller status, the LLM will predict a higher rating, consistent with expected relationships.

\subsubsection{Addressing the Cold Start Problem}

The cold start problem in recommendation systems occurs when new users or new products enter the system without sufficient historical interaction data. The proposed LLM-based approach specifically addresses this challenge:

\textbf{For New Users:}
When a new user enters the IoT-based shopping environment (e.g., through a mobile app or smart device), the LLM can generate initial recommendations based on:
\begin{itemize}
\item Product features (category, price, reviews) that the user might interact with
\item Contextual information from IoT devices (location, time, device type)
\item General knowledge embedded in the LLM from pre-training on large text corpora
\end{itemize}

The LLM leverages its pre-trained knowledge about product categories, typical user preferences, and semantic relationships to make reasonable initial recommendations even without user history.

\textbf{For New Products:}
When new products are added to the catalog, the LLM can predict ratings based on:
\begin{itemize}
\item Product descriptions and metadata
\item Similarity to existing products in the same category
\item General patterns learned from the training data
\end{itemize}

This capability is particularly valuable in IoT environments where new products are frequently added to smart retail systems.

\textbf{Mathematical Formulation:}
For a new user $u_{\text{new}}$ with no interaction history, the LLM generates an initial rating prediction:
\begin{equation}
r_{\text{initial}}(u_{\text{new}}, p) = \text{LLM}(f(\text{product\_features}(p), \text{context}(u_{\text{new}})))
\label{eq:cold_start}
\end{equation}
where $\text{context}(u_{\text{new}})$ includes IoT-derived contextual information such as location, time, and device type. This initial prediction is then refined as the user interacts with the system.

\subsubsection{Advantages Over Conventional Methods}

The proposed LLM-based approach offers several advantages:
\begin{enumerate}
\item \textbf{Semantic Understanding:} Unlike KNN or mean imputation, the LLM understands semantic relationships between product features, enabling more accurate imputation.
\item \textbf{Contextual Awareness:} The LLM incorporates contextual information from IoT devices, making recommendations more relevant to the user's current situation.
\item \textbf{Cold Start Mitigation:} The LLM's pre-trained knowledge allows it to make reasonable predictions even for new users or products.
\item \textbf{Scalability:} Once trained, the LLM can process imputation requests efficiently, making it suitable for real-time recommendation systems in IoT environments.
\end{enumerate}

Through enhancing the datasets using precisely imputed values, the LLM enables a wider range of insights into item characteristics and user behavior. This leads to more customized and relevant recommendations, efficiently tackling problems such as data sparsity that frequently delay conventional recommendation models. The LLM's performance demonstrates significant improvements compared to existing approaches, particularly in sparse data scenarios common in IoT-based shopping environments.

\subsection{Proposed Methodology}

\subsubsection{Traditional SVD}

The conventional product recommendation model uses the collaborative filtering based technique to recommend products to the users in terms of their preference. The Figure~\ref{fig:traditional_svd} represent the process of conventional SVD.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{media/image2.png}
\caption{Process of Traditional Product Recommendation}
\label{fig:traditional_svd}
\end{figure}

Figure~\ref{fig:traditional_svd} represents the process of traditional product recommendation. The process begins with collecting the dataset from the Amazon product review dataset, which is provided as input to the traditional recommendation model. The conventional SVD uses a collaborative filtering process to recommend products to customers. This collaborative filtering captures various collections of user preferences. Based on the dataset, product recommendations are ensured by comprising ratings of active users. Through employing SVD, collaborative filtering uses matrix factorization techniques that decompose the user-item matrix into lower-dimensional matrices signifying latent factors. The user-item matrix comprises ratings of users for several products in the context of product recommendation models. Typically, SVD may forecast relationships and unseen patterns among users and products by decomposing the matrix. The system includes all products in the dataset that users have not rated to create recommendations. To obtain forecasted scores, these unrated products are processed by the collaborative filtering model using SVD. Based on previous ratings, the forecasted scores identify the actual products purchased by users. However, this conventional SVD approach is employed for low-rank approximation of the rating matrix. On the other hand, conventional SVD is not able to handle the maximum portion of unseen ratings effectively, particularly in sparse data scenarios common in IoT-based shopping environments.

\subsubsection{Proposed Significant Latent Core Factor SVD}

To tackle the problem faced by traditional SVD, the proposed research employs the significant latent core factor SVD. This technique enhance the proposed model by accurate recommendation of products to the users. The entire process of proposed research is represented in the Figure~\ref{fig:proposed_model}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{media/image3.png}
\caption{Entire Process of Proposed Model}
\label{fig:proposed_model}
\end{figure}

Figure~\ref{fig:proposed_model} depicts the entire process of the proposed model. After pre-processing, the organized and filled dataset initiates matrix preparation for the user-item matrix. The matrix form is fed as input to the proposed significant latent core factor SVD. Due to challenges faced by traditional SVD, the proposed research includes extended latent core factor calculation, which is an important method employed in product recommendation models. The proposed extended latent core factor technique improves conventional SVD by concentrating on capturing more refined relationships in the dataset. Through maintaining a comprehensive set of singular vectors and values, this proposed approach performs better in capturing the primary structure of item attributes and user preferences. This technique is especially helpful in situations with sparse data, which permits more precise forecasting of user ratings for unseen data. The proposed extended latent core factor evaluation plays a significant role in enhancing the relevance and precision of product recommendations through leveraging insights from the interaction of the user-item matrix. 

The proposed research employs significant eigenvalue retention. Maintaining significant eigenvalues is important because they are directly associated with the most influential latent factors. By concentrating on these essential values, the proposed model may potentially capture the primary structure of the dataset while filtering out less relevant and noisy information. This is frequently obtained by choosing threshold methods to estimate which singular values to maintain based on their magnitude. When using this approach in the product recommendation system, maintaining only the prime singular values permits a low-rank approximation of the fundamental matrix. This approximation reduces computational complexity and improves prediction accuracy for unseen interactions in the user-item matrix. In the context of matrix factorization, the primary idea is to represent each user $u$ and product $p$ with low-dimensional latent factors $m_{u}$ and $m_{p}$. According to equation~\eqref{eq:rating}, the dyadic rating $r(u,p)$ from user $u$ to product $p$ is generally approximated as,

\begin{equation}
r_{b}(u,p) = m_{u}^{T}m_{p}
\label{eq:rating}
\end{equation}

Where, the rating forecast among $u$ and $p$ is denoted by $r_{b}(u,p)$, that is evaluated by the technique of latent core factorization. The primary form of matrix factorization technique may not seizure unambiguous characteristics. The process of proposed significant latent core factor SVD is represented in Algorithm~\ref{alg:svd}.

\begin{algorithm}[H]
\caption{Process of Proposed Significant Latent Core Factor SVD}
\label{alg:svd}
\begin{algorithmic}[1]
\REQUIRE $X$ - $p \times q$ matrix, $k$ - number of desired singular values ($k << \min(p, q)$)
\ENSURE $val\_U$ - $p \times k$ matrix of left singular vectors, $val\_\Sigma$ - $k \times k$ diagonal matrix of singular values, $val\_V$ - $q \times k$ matrix of right singular vectors
\STATE // Step 1: Initialize
\STATE $p, q = \text{dimensions of } X$
\STATE $v_1 = \text{random vector of size } n$
\STATE $v_1 = v_1 / ||v_1||$ // Normalize $v_1$
\STATE $val\_V = []$ // Matrix to store orthonormal vectors
\STATE $a = []$ // Diagonal elements
\STATE $b = []$ // Off-diagonal elements
\STATE // Step 2: Significant Eigenvalue Retention Iteration
\FOR{$j$ from $1$ to $k$}
    \STATE // Compute $w = X * v_j$
    \STATE $w = X * v_1$
    \STATE // Orthogonalize $w$ against previous vectors
    \FOR{$i$ from $1$ to $j$}
        \STATE $\alpha[i] = v_i^T * w$ // Inner product
        \STATE $w = w - a[i] * v_i$ // Remove component in direction of $v_i$
    \ENDFOR
    \STATE // Compute $b$
    \IF{$j > 1$}
        \STATE $w = w - b[j-1] * v_{j-1}$
    \ENDIF
    \STATE // Normalize $w$ to get $v_{j+1}$
    \STATE $b[j] = ||w||$ // Norm of $w$
    \IF{$b[j] > 0$}
        \STATE $v_{j+1} = w / b[j]$ // Normalize
    \ENDIF
    \STATE $V.\text{append}(v_j)$ // Store the orthonormal vector
    \STATE $a[j] = v_j^T * (X * v_j)$ // Compute $a[j]$
\ENDFOR
\STATE // Step 3: Construct Tridiagonal Matrix $T$
\STATE $T = \text{tridiagonal\_matrix}(a, b)$
\STATE // Step 4: Compute eigenvalues and eigenvectors of $T$
\STATE $\lambda, Z = \text{eigen\_decomposition}(T)$
\STATE // Step 5: Obtain singular values
\STATE $\Sigma = \text{diag}(\sqrt{\lambda})$ // Singular values
\STATE // Step 6: Compute $val\_U$ and $val\_V$
\STATE $val\_U = []$ // Initialize $val\_U$
\FOR{$j$ from $1$ to $k$}
    \STATE ${val\_U}_j = (X * v_j) / \Sigma[j]$ // Compute left singular vectors
    \STATE $val\_U.\text{append}({val\_U}_j)$
\ENDFOR
\RETURN $val\_U, val\_\Sigma, val\_V$
\end{algorithmic}
\end{algorithm}

The function of the proposed significant latent core factor SVD takes two inputs: $X$, which is the large matrix that needs to be analyzed, and $k$, which is the number of singular values to identify. Initially, the matrix dimensions of $X$ are estimated, and a random vector $v_{1}$ of size $n$ is created and normalized to ensure it has unit length. To store diagonal elements and orthonormal vectors, two empty lists are created: $val\_V$ and $a$. Additionally, $b$ stores another list for off-diagonal elements. The proposed significant latent core factor SVD runs for $k$ iterations. In each iteration, a new vector $w$ is evaluated by multiplying the matrix $X$ with the current vector $v_{j}$. To ensure that all vectors remain orthonormal, this vector is orthogonalized against all existing calculated vectors. This includes evaluating inner products and modifying $w$ by subtracting components in the directions of existing vectors. If the process is not in the initial iteration, an additional modification is created by subtracting a scaled version of the previous vector. The norm of $w$ is evaluated and stored in $b[j]$ after orthogonalization. If the norm is greater than zero, it is used to normalize $w$, producing the next $v_{j+1}$ orthonormal vector. Afterwards, the current vector is included in $val\_V$, and the diagonal element is evaluated as the inner product of $v_{j}$ with $X \cdot v_{j}$. The tridiagonal matrix $T$ is constructed from the $a$ diagonal elements and $b$ off-diagonal elements. This matrix captures the significant information required for eigenvalue decomposition. The eigenvalues $\lambda$ and eigenvectors $Z$ of $T$ are calculated. These eigenvalues correspond to squared singular values. The singular values are obtained by taking the square root of $\lambda$ and generating a diagonal matrix $\Sigma$. The left singular vectors $val\_U$ are calculated by transforming each orthonormal vector by $X$ and normalizing by the corresponding singular value. Finally, the function returns $val\_U$, $val\_\Sigma$, and $val\_V$, three matrices representing left singular vectors, singular values, and right singular vectors, respectively. Thus, the efficacy of SVD is enhanced by the proposed extended latent core factor calculation with significant eigenvalue retention, improving the significance of recommendations through leveraging the most significant latent factors that capture product characteristics and user behavior. This results in more accurate and personalized product recommendations for customers.

\subsubsection{Mathematical Comparison: Traditional SVD vs. Proposed Significant Latent Core Factor SVD}

To clearly distinguish the novelty of the proposed approach, we provide a detailed mathematical comparison between traditional SVD and the proposed significant latent core factor SVD.

\textbf{Traditional SVD Formulation:}
Traditional SVD decomposes a matrix $X \in \mathbb{R}^{m \times n}$ into three matrices:
\begin{equation}
X = U \Sigma V^T
\label{eq:traditional_svd}
\end{equation}
where $U \in \mathbb{R}^{m \times m}$ and $V \in \mathbb{R}^{n \times n}$ are orthogonal matrices, and $\Sigma \in \mathbb{R}^{m \times n}$ is a diagonal matrix containing singular values. For recommendation systems, a truncated SVD with rank $k$ is typically used:
\begin{equation}
X \approx U_k \Sigma_k V_k^T
\label{eq:truncated_svd}
\end{equation}
where $U_k \in \mathbb{R}^{m \times k}$, $\Sigma_k \in \mathbb{R}^{k \times k}$, and $V_k \in \mathbb{R}^{n \times k}$.

The computational complexity of traditional SVD is $O(mn^2)$ for full decomposition or $O(mnk)$ for truncated SVD using iterative methods. However, traditional SVD has limitations: (1) it treats all singular values equally, (2) it may retain noisy or less significant components, and (3) it struggles with highly sparse matrices common in recommendation systems.

\textbf{Proposed Significant Latent Core Factor SVD Formulation:}
The proposed method introduces two key algorithmic improvements:

\textit{1. Significant Eigenvalue Retention:} Instead of retaining all $k$ singular values, the proposed method employs a threshold-based selection that retains only the most significant eigenvalues. The selection criterion is:
\begin{equation}
\sigma_i \geq \theta \cdot \sigma_{\max}
\label{eq:threshold}
\end{equation}
where $\sigma_i$ is the $i$-th singular value, $\sigma_{\max}$ is the maximum singular value, and $\theta$ is a threshold parameter (typically 0.01-0.1). This ensures that only latent factors with substantial contribution to the matrix structure are retained.

\textit{2. Extended Latent Core Factor Calculation:} The proposed method constructs a tridiagonal matrix $T$ through an iterative Lanczos-like process:
\begin{equation}
T = \begin{pmatrix}
\alpha_1 & \beta_1 & 0 & \cdots & 0 \\
\beta_1 & \alpha_2 & \beta_2 & \cdots & 0 \\
0 & \beta_2 & \alpha_3 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & \alpha_k
\end{pmatrix}
\label{eq:tridiagonal}
\end{equation}
where $\alpha_j = v_j^T (X^T X) v_j$ and $\beta_j = ||w_j||$ are computed through the orthogonalization process described in Algorithm~\ref{alg:svd}. The eigenvalues $\lambda$ of $T$ are then used to compute singular values as $\sigma = \sqrt{\lambda}$.

\textbf{Key Algorithmic Differences:}
\begin{enumerate}
\item \textbf{Selective Retention:} Traditional SVD retains the top $k$ singular values regardless of their magnitude. The proposed method retains only singular values above a significance threshold, reducing noise and improving prediction accuracy for sparse data.
\item \textbf{Iterative Refinement:} The proposed method uses an iterative Lanczos-like process that builds orthonormal vectors incrementally, allowing for early termination when convergence is detected, reducing computational overhead.
\item \textbf{Sparse Matrix Optimization:} The proposed method is specifically optimized for sparse matrices through the tridiagonal construction, which requires fewer matrix-vector multiplications compared to full SVD decomposition.
\end{enumerate}

\textbf{Mathematical Advantage:}
The proposed method provides a more accurate low-rank approximation by:
\begin{equation}
||X - \hat{X}_{\text{proposed}}||_F \leq ||X - \hat{X}_{\text{traditional}}||_F
\label{eq:approximation}
\end{equation}
where $\hat{X}_{\text{proposed}} = U_k' \Sigma_k' V_k'^T$ uses only the significant singular values, and $||\cdot||_F$ denotes the Frobenius norm. This improvement is particularly pronounced in sparse recommendation matrices where many singular values are near-zero and contribute primarily to noise.

\subsubsection{Integration with IoT and Edge Computing Environments}

The proposed recommendation system is designed to function effectively within smart retail IoT environments and on edge devices. The system architecture addresses several IoT-specific challenges:

\textbf{1. Real-time Processing on Edge Devices:}
The proposed significant latent core factor SVD is computationally efficient, making it suitable for edge devices with limited processing power. The selective eigenvalue retention reduces the dimensionality of the problem, enabling faster inference. The computational complexity is $O(mnk)$ for the iterative process, but with early termination and threshold-based selection, the effective complexity is often $O(mnk')$ where $k' < k$ is the number of significant eigenvalues retained.

\textbf{2. Sparse Data Handling:}
IoT environments generate sparse data streams from various sensors (RFID, beacons, smart shelves). The proposed method's optimization for sparse matrices makes it ideal for processing such data. The tridiagonal matrix construction requires only $O(\text{nnz}(X) \cdot k)$ operations where $\text{nnz}(X)$ is the number of non-zero elements, significantly less than full matrix operations.

\textbf{3. LLM-based Feature Extraction for IoT Context:}
The LLM component processes contextual information from IoT devices, including location data, time of day, device type, and user behavior patterns. This contextual enrichment helps address the cold start problem in IoT scenarios where new users or devices enter the system without historical data.

\textbf{4. Distributed Processing:}
For large-scale IoT deployments, the proposed method can be distributed across multiple edge devices. The matrix factorization can be performed locally on edge devices, with only the significant latent factors transmitted to a central server for aggregation, reducing bandwidth requirements and preserving user privacy.

\subsection{Computational Complexity Analysis}

To evaluate the feasibility of the proposed model for real-time recommendation updates in large-scale e-commerce platforms, particularly in IoT environments, we provide a detailed complexity analysis.

\textbf{Time Complexity:}
\begin{itemize}
\item \textbf{LLM Pre-processing:} The LLM-based data imputation has time complexity $O(n \cdot L \cdot d)$ where $n$ is the number of products with missing values, $L$ is the sequence length (512 tokens), and $d$ is the model dimension. For batch processing, this reduces to $O(n \cdot L \cdot d / B)$ where $B$ is the batch size.
\item \textbf{Matrix Construction:} Building the user-item matrix from the preprocessed data requires $O(m \cdot n)$ operations where $m$ is the number of users and $n$ is the number of products.
\item \textbf{Proposed SVD Decomposition:} The significant latent core factor SVD has time complexity $O(mnk' + k'^3)$ where $k'$ is the number of significant eigenvalues retained (typically $k' < k$). The first term accounts for the iterative Lanczos-like process, and the second term accounts for eigenvalue decomposition of the tridiagonal matrix.
\item \textbf{Recommendation Generation:} Generating recommendations for all users requires $O(m \cdot n \cdot k')$ operations for matrix multiplication.
\end{itemize}

\textbf{Space Complexity:}
\begin{itemize}
\item \textbf{LLM Model:} The BART-base model requires $O(d^2)$ space where $d$ is the model dimension (768 for BART-base), approximately 560MB.
\item \textbf{User-Item Matrix:} Storage requires $O(m \cdot n)$ space. For sparse matrices, this can be reduced to $O(\text{nnz})$ where $\text{nnz}$ is the number of non-zero entries.
\item \textbf{SVD Matrices:} The decomposed matrices require $O(mk' + nk' + k')$ space.
\end{itemize}

\textbf{Total Complexity:}
The overall time complexity is $O(n \cdot L \cdot d / B + mnk' + k'^3 + mnk')$, which for typical values ($n=10^6$, $m=10^5$, $k'=100$, $B=32$) results in approximately $O(10^{11})$ operations. With modern hardware and optimized implementations, this translates to processing times of minutes to hours for initial model training, but real-time inference for new recommendations requires only $O(mk' + nk')$ operations, making it feasible for edge devices.

\textbf{Optimization for Edge Devices:}
For IoT and edge computing environments, the proposed method can be optimized through:
\begin{enumerate}
\item \textbf{Incremental Updates:} Instead of recomputing the full SVD, incremental updates can be performed when new interactions arrive, reducing complexity to $O(k'^2)$ per update.
\item \textbf{Model Quantization:} The LLM can be quantized to reduce memory footprint from 560MB to approximately 140MB, enabling deployment on resource-constrained edge devices.
\item \textbf{Distributed Processing:} The computation can be distributed across multiple edge devices, with each device handling a subset of users or products.
\end{enumerate}

\section{Result and Discussion}

This section presents the experimental outcomes of the proposed significant latent core factor SVD for personalized product recommendation, including comparisons with traditional SVD and state-of-the-art methods.

\subsection{Performance Metrics}

Performance metrics are primarily used for observing the efficiency of the proposed research by utilizing metrics like RMSE and MSE value.

\begin{enumerate}
\item \textbf{MSE}

Mean Squared Error measures the average squared difference between predicted and actual ratings. Lower MSE values indicate better prediction quality, with values closer to zero representing superior performance. The formula for MSE is given in equation~\eqref{eq:mse}

\begin{equation}
MSE = \frac{1}{n}\sum_{i=1}^{n}\left(Y_{i} - \hat{Y}_{i}\right)^{2}
\label{eq:mse}
\end{equation}

\item \textbf{RMSE}

Root Mean Squared Error is deliberated as the standard deviation of difference between residuals such as actual and predicted values. Lesser RMSE values denotes that the data fits well whereas high RMSE values suggest with less precise predictions and greater errors. RMSE is calculated using equation~\eqref{eq:rmse}

\begin{equation}
RMSE = \sqrt{\frac{\sum_{i=1}^{N}(actual - predicted)^{2}}{N}}
\label{eq:rmse}
\end{equation}
\end{enumerate}

\subsection{EDA (Exploratory Data Analysis)}

This section deliberates the experimental outcomes of the proposed significant latent core factor SVD.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{media/image4.png}
\caption{Price Distribution by Category}
\label{fig:price_dist}
\end{figure}

Figure~\ref{fig:price_dist} depicts the price distribution by category of top 10 products. Each classification has an important count of outliers that recommends that some of the items are extremely costly and most of the products are reasonably priced. In this plot, Men's Shoes, Women's Jewelry and Toys \& Games have maximum outliers with prices beyond 3500 dollars. Most of the products in the categories are cheap, still a minimum percentage of high end or luxury items drive the extreme prices.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{media/image5.png}
\caption{Analysis of Average Rating and Best Seller Status}
\label{fig:rating_analysis}
\end{figure}

Figure~\ref{fig:rating_analysis} depicts the average rating verses best seller status. This plot evaluates the distribution of average ratings provided by the uses for products in terms of their best seller status. The plot represents both there is a 4.5 star rating for both non-best selling and best-selling products. The whiskers represent that ratings in both groups are low as 3 stars which includes few extensive outliers dropping below rating of 2 stars and without star rating. The high rating is not extensive to best sellers, while best sellers represent les variability in ratings provided by the customers.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{media/image6.png}
\caption{Top 10 Product Categories by Count}
\label{fig:categories}
\end{figure}

Figure~\ref{fig:categories} depicts the top 10 product categories by count. The plots shows that the highest product count is achieved by Girls' Clothing with 30000, the next position is achieved by Boys' Clothing with 25000. The least count is achieved by Women's Jewelry with 170000 of count.

\subsection{Performance Analysis}

\begin{table}[H]
\centering
\caption{Performance Analysis of MSE}
\label{tab:mse}
\begin{tabular}{lc}
\toprule
\textbf{Model/Metrics} & \textbf{MSE} \\
\midrule
Traditional SVD & 0.4585 \\
Proposed SVD & 0.3246 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{media/image7.png}
\caption{Performance Analysis of MSE}
\label{fig:mse_perf}
\end{figure}

Table~\ref{tab:mse} represent the performance analysis of MSE. The proposed research compare the performance of traditional SVD with proposed SVD. Where the proposed SVD achieves less error time with 0.3246 when compare to traditional SVD with 0.4585. The graphical representation of Table~\ref{tab:mse} is depicted in the Figure~\ref{fig:mse_perf}.

\begin{table}[H]
\centering
\caption{Performance Analysis of RMSE}
\label{tab:rmse}
\begin{tabular}{lc}
\toprule
\textbf{Model/Metrics} & \textbf{RMSE} \\
\midrule
Traditional SVD & 0.6771 \\
Proposed SVD & 0.5696 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{media/image8.png}
\caption{Performance Analysis of RMSE}
\label{fig:rmse_perf}
\end{figure}

Table~\ref{tab:rmse} represent the performance analysis of RMSE. The proposed research compare the performance of traditional SVD with proposed SVD. Where the proposed SVD achieves less error time with 0.5696 when compare to traditional SVD with 0.6771. The graphical representation of Table~\ref{tab:rmse} is depicted in the Figure~\ref{fig:rmse_perf}.

\subsection{Comparative Analysis}

\begin{table}[H]
\centering
\caption{Comparative Analysis with State-of-the-Art Methods}
\label{tab:comparative}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{MSE} & \textbf{RMSE} \\
\midrule
Traditional SVD & 0.4585 & 0.6771 \\
Existing UTER~\cite{ref51} & 0.9653 & 0.9825 \\
Existing MCNN~\cite{ref52} & 0.8978 & 0.9475 \\
LightGCN (Baseline) & 0.4123 & 0.6421 \\
BERT4Rec (Baseline) & 0.3891 & 0.6238 \\
\textbf{Proposed SVD} & \textbf{0.3246} & \textbf{0.5696} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{media/image9.png}
\caption{Comparative Analysis of RMSE with State-of-the-Art Methods}
\label{fig:comparative}
\end{figure}

Table~\ref{tab:comparative} presents a comprehensive comparative analysis of the proposed method against traditional SVD, existing methods (UTER and MCNN), and state-of-the-art recommendation models (LightGCN and BERT4Rec). The proposed significant latent core factor SVD achieves the lowest RMSE value of 0.5696, representing improvements of 15.9\% over traditional SVD (0.6771), 9.1\% over LightGCN (0.6421), 8.7\% over BERT4Rec (0.6238), 42.0\% over UTER (0.9825), and 39.9\% over MCNN (0.9475).

\textbf{Comparison with LightGCN:}
LightGCN is a state-of-the-art graph neural network-based recommendation method that simplifies Graph Convolutional Networks by removing feature transformation and nonlinear activation. While LightGCN achieves strong performance (RMSE: 0.6421), the proposed method outperforms it by 9.1\%. The advantage of the proposed method lies in its ability to handle sparse data more effectively through significant eigenvalue retention, which is particularly beneficial for IoT-based shopping scenarios with limited interaction data.

\textbf{Comparison with BERT4Rec:}
BERT4Rec is a bidirectional sequential recommendation model based on BERT architecture that captures both left and right context in user behavior sequences. BERT4Rec achieves RMSE of 0.6238, which is competitive but still 8.7\% higher than the proposed method. The proposed method's advantage comes from its combination of LLM-based feature extraction (which provides rich semantic understanding similar to BERT) and the optimized SVD decomposition that efficiently handles the high-dimensional feature space.

\textbf{Key Advantages:}
\begin{enumerate}
\item \textbf{Sparse Data Handling:} The proposed method's significant eigenvalue retention mechanism makes it more robust to sparse data compared to LightGCN and BERT4Rec, which require denser interaction graphs or sequences.
\item \textbf{Computational Efficiency:} The proposed method has lower computational complexity than graph-based methods (LightGCN) and sequence models (BERT4Rec), making it more suitable for real-time recommendations in IoT environments.
\item \textbf{Cold Start Performance:} The LLM component provides better cold start capabilities compared to LightGCN (which requires user-item graph structure) and BERT4Rec (which requires user behavior sequences).
\end{enumerate}

Figure~\ref{fig:comparative} visually depicts the comparative analysis, clearly showing the superior performance of the proposed method across all evaluation metrics.

\section{Conclusion and Future Work}

The product recommendation system has enhanced the performance of e-commerce, particularly in IoT-based smart retail environments, by evaluating customer ratings and reviews. Most existing studies have employed content-based collaborative filtering and SVD. SVD has been considered an efficient approach for product recommendation. However, the limitations of traditional SVD delay the process of recommending products to customers more precisely, as SVD struggles with unseen data and sparse matrices common in IoT shopping scenarios. To address this problem, the proposed research has employed significant latent core factor SVD to recommend products to customers based on their previous ratings and purchases, with specific optimizations for IoT and edge computing environments.

The proposed research has used Large Language Models (LLMs) to enhance the process of feature extraction and data imputation. The LLM component has aided in forecasting missing values and filling them with semantically meaningful predictions based on existing data. Additionally, it accurately recommends products even when there is minimal interaction data, effectively addressing the cold start problem for new users and products. The proposed significant latent core factor SVD has been evaluated using the Amazon product review dataset. The performance of the proposed significant latent core factor SVD has been evaluated using MSE and RMSE metrics. When compared to traditional SVD and state-of-the-art methods including LightGCN and BERT4Rec, the proposed significant latent core factor SVD has achieved superior performance with MSE of 0.3246 and RMSE of 0.5696, representing improvements of 15.9\% over traditional SVD and 8.7-9.1\% over modern deep learning approaches.

The mathematical analysis demonstrates that the proposed method provides a more accurate low-rank approximation through significant eigenvalue retention and extended latent core factor calculation, distinguishing it clearly from traditional SVD variants. The computational complexity analysis confirms the feasibility of the proposed method for real-time recommendation updates in large-scale e-commerce platforms and edge devices. The integration with IoT environments enables the system to process sparse data streams from various sensors and provide contextual recommendations based on real-time shopping data.

Future work of the proposed research will focus on: (1) extending the method to other developing fields with enhanced personalization recommendations based on existing data, (2) exploring federated learning approaches for distributed IoT environments while preserving user privacy, (3) investigating adaptive threshold selection methods for significant eigenvalue retention, and (4) developing lightweight LLM variants specifically optimized for edge devices with limited computational resources.

% Bibliography
\begin{thebibliography}{99}

\bibitem{ref1} C. Li, I. Ishak, H. Ibrahim, M. Zolkepli, F. Sidi, and C. J. I. A. Li, ``Deep Learning-Based Recommendation System: Systematic Review and Classification,'' \textit{IEEE Access}, 2023.

\bibitem{ref2} D. Roy and M. J. J. o. B. D. Dutta, ``A systematic review and research perspective on recommender systems,'' \textit{Journal of Big Data}, vol. 9, no. 1, p. 59, 2022.

\bibitem{ref3} H. Zhou, F. Xiong, and H. J. A. S. Chen, ``A comprehensive survey of recommender systems based on deep learning,'' \textit{Applied Sciences}, vol. 13, no. 20, p. 11378, 2023.

\bibitem{ref4} A. Da'u and N. J. A. I. R. Salim, ``Recommendation system based on deep learning methods: a systematic review and new directions,'' \textit{Artificial Intelligence Review}, vol. 53, no. 4, pp. 2709-2748, 2020.

\bibitem{ref5} M. Nasir and C. I. J. S. C. S. Ezeife, ``A survey and taxonomy of sequential recommender systems for e-commerce product recommendation,'' \textit{J SN Computer Science}, vol. 4, no. 6, p. 708, 2023.

\bibitem{ref6} A. Torkashvand, S. M. Jameii, A. J. N. C. Reza, and Applications, ``Deep learning-based collaborative filtering recommender systems: A comprehensive and systematic review,'' \textit{Neural Computing Applications}, vol. 35, no. 35, pp. 24783-24827, 2023.

\bibitem{ref7} A. Daza, N. D. G. Rueda, M. S. A. Snchez, W. F. R. Espritu, and M. E. C. J. I. J. o. I. M. D. I. Quiones, ``Sentiment Analysis on E-Commerce Product Reviews Using Machine Learning and Deep Learning Algorithms: A Bibliometric Analysisand Systematic Literature Review, Challenges and Future Works,'' \textit{International Journal of Information Management Data Insights}, vol. 4, no. 2, p. 100267, 2024.

\bibitem{ref8} A. Suresh, M. Carmel, and M. J. I. J. o. A. S. Belinda, ``A comprehensive study of hybrid recommendation systems for e-commerce applications,'' \textit{International Journal of Advanced Science Technology} vol. 29, no. 3, pp. 4089-4101, 2020.

\bibitem{ref9} L. J. M. I. S. Liu, ``eCommerce Personalized Recommendation Based on Machine Learning Technology,'' \textit{Mobile Information Systems}, vol. 2022, no. 1, p. 1761579, 2022.

\bibitem{ref10} K. Wu and K. J. Chi, ``Enhanced e-commerce customer engagement: A comprehensive three-tiered recommendation system,'' \textit{Journal of Knowledge Learning Science Technology} vol. 2, no. 3, pp. 348-359, 2023.

\bibitem{ref11} N. Chabane \textit{et al.}, ``Intelligent personalized shopping recommendation using clustering and supervised machine learning algorithms,'' \textit{Plos one}, vol. 17, no. 12, p. e0278364, 2022.

\bibitem{ref12} A. Hasan, Z. B. Yusof, and M. J. I. J. o. A. M. L. Karim, ``Machine Learning Algorithms for Personalized Product Recommendations and Enhanced Customer Experience in E-Commerce Platforms,'' \textit{International Journal of Applied Machine Learning}, vol. 4, no. 11, pp. 1-15, 2024.

\bibitem{ref13} S. Sharma, V. Rana, and V. J. I. J. o. I. M. D. I. Kumar, ``Deep learning based semantic personalized recommendation system,'' \textit{International Journal of Information Management Data Insights}, vol. 1, no. 2, p. 100028, 2021.

\bibitem{ref14} H. Bastani, P. Harsha, G. Perakis, D. J. M. Singhvi, and S. O. Management, ``Learning personalized product recommendations with customer disengagement,'' \textit{Manufacturing Service Operations Management}, vol. 24, no. 4, pp. 2010-2028, 2022.

\bibitem{ref15} J. Xu, Z. Hu, and J. J. J. o. I. P. S. Zou, ``Personalized product recommendation method for analyzing user behavior using DeepFM,'' \textit{Journal of Information Processing Systems}, vol. 17, no. 2, pp. 369-384, 2021.

\bibitem{ref16} D.-N. Nguyen, V.-H. Nguyen, T. Trinh, T. Ho, H.-S. J. J. o. O. I. T. Le, Market,, and Complexity, ``A personalized product recommendation model in e-commerce based on retrieval strategy,'' \textit{Journal of Open Innovation: Technology, Market, Complexity}, vol. 10, no. 2, p. 100303, 2024.

\bibitem{ref17} A. Nikolajeva and A. J. E. Teilans, ``Machine Learning Technology Overview In Terms Of Digital Marketing And Personalization,'' \textit{ECMS}, pp. 125-130, 2021.

\bibitem{ref18} N. R. J. J. o. A.-A. S. D. Mitta, ``Enhancing E-Commerce with Deep Learning: Techniques for Personalized Recommendations, Customer Segmentation, and Dynamic Pricing,'' \textit{Journal of AI-Assisted Scientific Discovery}, vol. 3, no. 2, pp. 496-534, 2023.

\bibitem{ref19} C.-Z. Tsai, H. Huang, C.-J. Wei, and M.-C. Chiu, ``Apply deep learning to build a personalized attraction recommendation system in a smart product service system,'' in \textit{Leveraging Transdisciplinary Engineering in a Changing and Connected World}: IOS Press, 2023, pp. 151-160.

\bibitem{ref20} R. J. K. Almahmood and A. J. A. S. Tekerek, ``Issues and solutions in deep learning-enabled recommendation systems within the e-commerce field,'' vol. 12, no. 21, p. 11256, 2022.

\bibitem{ref21} A. Iftikhar, M. A. Ghazanfar, M. Ayub, Z. Mehmood, and M. J. I. A. Maqsood, ``An improved product recommendation method for collaborative filtering,'' \textit{IEEE Access}, vol. 8, pp. 123841-123857, 2020.

\bibitem{ref22} M. R. R. Renukadevi, K. Sathishkumar, E. Boopathi Kumar, S. Janarthanam, Azimov Abdikhamidullo Kholmanovich, ``An Improved Collaborative User Product Recommendation System Using Computational Intelligence with Association Rules '' \textit{Communications on Applied Nonlinear Analysis}, vol. 31, 2024.

\bibitem{ref23} N. Vaishnavi and B. J. J. o. E. S. Kalpana, ``Sentiment Based Product Recommendation System Using Machine Learning Techniques,'' \textit{Journal of Engineering Science Technology Review}, vol. 17, no. 1, 2024.

\bibitem{ref24} N. Padhy, S. Suman, T. S. Priyadarshini, and S. J. E. P. Mallick, ``A Recommendation System for E-Commerce Products Using Collaborative Filtering Approaches,'' \textit{Engineering Proceedings}, vol. 67, no. 1, p. 50, 2024.

\bibitem{ref25} C. Udokwu, R. Zimmermann, F. Darbanian, T. Obinwanne, and P. J. P. C. S. Brandtner, ``Design and Implementation of a Product Recommendation System with Association and Clustering Algorithms,'' \textit{Procedia Computer Science}, vol. 219, pp. 512-520, 2023.

\bibitem{ref26} L. Kang and Y. J. H. Wang, ``Efficient and accurate personalized product recommendations through frequent item set mining fusion algorithm,'' \textit{Heliyon}, vol. 10, no. 3, 2024.

\bibitem{ref27} N. Ramshankar and P. J. S. Joe Prathap, ``A novel recommendation system enabled by adaptive fuzzy aided sentiment classification for E-commerce sector using black hole-based grey wolf optimization,'' \textit{Sdhan}, vol. 46, no. 3, p. 125, 2021.

\bibitem{ref28} S. G. K. Patro \textit{et al.}, ``A hybrid action-related K-nearest neighbour (HAR-KNN) approach for recommendation systems,'' \textit{IEEE Access}, vol. 8, pp. 90978-90991, 2020.

\bibitem{ref29} Y. Gulzar, A. A. Alwan, R. M. Abdullah, A. Z. Abualkishik, and M. J. S. Oumrani, ``OCA: ordered clustering-based algorithm for E-commerce recommendation system,'' \textit{Sustainability} vol. 15, no. 4, p. 2947, 2023.

\bibitem{ref30} F. T. Abdul Hussien, A. M. S. Rahma, and H. B. J. S. Abdulwahab, ``An e-commerce recommendation system based on dynamic analysis of customer behavior,'' \textit{Sustainability}, vol. 13, no. 19, p. 10786, 2021.

\bibitem{ref31} M. Nasir, C. I. Ezeife, A. J. S. N. A. Gidado, and Mining, ``Improving e-commerce product recommendation using semantic context and sequential historical purchases,'' \textit{Social Network Analysis Mining}, vol. 11, no. 1, p. 82, 2021.

\bibitem{ref32} I. Islek, S. G. J. E. C. R. Oguducu, and Applications, ``A hierarchical recommendation system for E-commerce using online user reviews,'' \textit{Electronic Commerce Research Applications}, vol. 52, p. 101131, 2022.

\bibitem{ref33} Q. Li, X. Li, B. Lee, and J. J. A. S. Kim, ``A hybrid CNN-based review helpfulness filtering model for improving e-commerce recommendation Service,'' \textit{Applied Sciences}, vol. 11, no. 18, p. 8613, 2021.

\bibitem{ref34} M. Nasir, C. I. J. I. J. o. D. S. Ezeife, and Analytics, ``Semantic enhanced Markov model for sequential E-commerce product recommendation,'' \textit{International Journal of Data Science Analytics}, vol. 15, no. 1, pp. 67-91, 2023.

\bibitem{ref35} L. Li, Z. Zhang, and S. J. S. P. Zhang, ``Hybrid algorithm based on content and collaborative filtering in recommendation system optimization and simulation,'' \textit{Scientific Programming}, vol. 2021, no. 1, p. 7427409, 2021.

\bibitem{ref36} S. G. K. Patro, B. K. Mishra, S. K. Panda, R. Kumar, H. V. Long, and D. J. S. C. Taniar, ``Cold start aware hybrid recommender system approach for E-commerce users,'' \textit{Soft Computing}, vol. 27, no. 4, pp. 2071-2091, 2023.

\bibitem{ref37} K. Xu, H. Zhou, H. Zheng, M. Zhu, and Q. J. Xin, ``Intelligent Classification and Personalized Recommendation of E-commerce Products Based on Machine Learning,'' \textit{arXiv preprint arXiv:.19345} 2024.

\bibitem{ref38} D.-N. Nguyen, V.-H. Nguyen, T. Trinh, T. Ho, and H.-S. J. Le, ``A personalized product recommendation model in e-commerce based on retrieval strategy,'' \textit{Journal of Open Innovation: Technology, Market, Complexity} vol. 10, no. 2, p. 100303, 2024.

\bibitem{ref39} M. Loukili, F. Messaoudi, and M. J. El Ghazi, ``Machine learning based recommender system for e-commerce,'' \textit{IAES International Journal of Artificial Intelligence} vol. 12, no. 4, pp. 1803-1811, 2023.

\bibitem{ref40} F. Colace, D. Conte, M. De Santo, M. Lombardi, D. Santaniello, and C. J. Valentino, ``A content-based recommendation approach based on singular value decomposition,'' \textit{Connection Science} vol. 34, no. 1, pp. 2158-2176, 2022.

\bibitem{ref41} S. K. Addagarla and A. Amalanathan, ``Probabilistic Unsupervised Machine Learning Approach for a Similar Image Recommender System for E-Commerce,'' \textit{Symmetry} vol. 12, no. 11, p. 1783, 2020.

\bibitem{ref42} W.-E. Kong, T.-E. Tai, P. Naveen, and H. A. J. Santoso, ``Performance evaluation on E-commerce recommender system based on KNN, SVD, CoClustering and ensemble approaches,'' \textit{Journal of Informatics Web Engineering} vol. 3, no. 3, pp. 63-76, 2024.

\bibitem{ref43} P. Patil, S. U. Kadam, E. Aruna, A. More, R. Balajee, and B. N. K. J. Rao, ``Recommendation System for E-Commerce Using Collaborative Filtering,'' \textit{Journal Europen des Systmes Automatiss} vol. 57, no. 4, p. 1145, 2024.

\bibitem{ref44} B. Hssina, A. Grota, and M. J. Erritali, ``Recommendation system using the k-nearest neighbors and singular value decomposition algorithms,'' \textit{Int. J. Electr. Comput. Eng} vol. 11, no. 6, pp. 5541-5548, 2021.

\bibitem{ref45} S. Y. Chang, H.-C. Wu, K. Yan, X. Chen, S. C.-H. Huang, and Y. J. Wu, ``Personalized multimedia recommendation systems using higher-order tensor singular-value-decomposition,'' \textit{IEEE Transactions on Broadcasting} vol. 70, no. 1, pp. 148-160, 2023.

\bibitem{ref46} H. J. Du, ``Teaching Research on E-commerce Micro-media Recommendation Data Analysis by Integrating Singular Value Decomposition Algorithm,'' \textit{Journal of Electrical Systems} vol. 20, no. 9s, pp. 204-211, 2024.

\bibitem{ref47} A. Tripathi, R. Jain, and K. Tahiliani, ``A recommender system based on variants of singular value decomposition,'' in \textit{Data Analytics for Intelligent Systems: Techniques and solutions}: IOP Publishing Bristol, UK, 2024, pp. 11-1-11-15.

\bibitem{ref48} S. Krepych and I. J. Spivak, ``Improvement of SVD algorithm to increase the efficiency of recommendation systems,'' \textit{Advanced Information Systems} vol. 5, no. 4, pp. 55-59, 2021.

\bibitem{ref49} K. Przystupa \textit{et al.}, ``Distributed singular value decomposition method for fast data processing in recommendation systems,'' \textit{Energies}, vol. 14, no. 8, p. 2284, 2021.

\bibitem{ref50} S. J. Rahman, ``Extended Collaborative Filtering Recommendation System with Adaptive KNN and SVD,'' \textit{International Journal of Engineering Management Research} vol. 13, no. 4, 2023.

\bibitem{ref51} S. Sachin, A. Tripathi, N. Mahajan, S. Aggarwal, and P. J. S. C. S. Nagrath, ``Sentiment analysis using gated recurrent neural networks,'' \textit{SN Computer Science} vol. 1, pp. 1-13, 2020.

\bibitem{ref52} Y. M. Latha and B. S. J. E. j. Rao, ``Amazon product recommendation system based on a modified convolutional neural network,'' \textit{ETRI journal} vol. 46, no. 4, pp. 633-647, 2024.

\end{thebibliography}

\end{document}
